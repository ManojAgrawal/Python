{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN example with tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/u606941/VA Scripts/rnn_test.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple time series with spikes every 6 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series\n",
       "0     200\n",
       "1      42\n",
       "2      42\n",
       "3      42\n",
       "4      41\n",
       "5      41\n",
       "6     202\n",
       "7      41\n",
       "8      42\n",
       "9      39"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dataframe series into an array and then create X_train and Y_train by creating lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.array(df)\n",
    "y_train = arr[1:].copy()\n",
    "X_train = arr[:-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200,  42],\n",
       "       [ 42,  42],\n",
       "       [ 42,  42],\n",
       "       [ 42,  41],\n",
       "       [ 41,  41],\n",
       "       [ 41, 202],\n",
       "       [202,  41],\n",
       "       [ 41,  42],\n",
       "       [ 42,  39],\n",
       "       [ 39,  41],\n",
       "       [ 41,  40],\n",
       "       [ 40, 201],\n",
       "       [201,  44],\n",
       "       [ 44,  42],\n",
       "       [ 42,  45],\n",
       "       [ 45,  42],\n",
       "       [ 42,  43],\n",
       "       [ 43, 203],\n",
       "       [203,  43],\n",
       "       [ 43,  43],\n",
       "       [ 43,  44],\n",
       "       [ 44,  42],\n",
       "       [ 42,  45]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[X_train,y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 23 steps with single feature input and single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 23\n",
    "n_inputs = 1\n",
    "n_neurons = 10\n",
    "n_outputs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### declare placeholders and declare a Basic RNN cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, \\\n",
    "                                                                activation = tf.nn.relu), output_size = n_outputs)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5034.41\n",
      "4998.32\n",
      "4963.48\n",
      "4929.55\n",
      "4896.09\n",
      "4863.46\n",
      "4834.74\n",
      "4817.87\n",
      "4807.08\n",
      "4798.63\n",
      "4789.47\n",
      "4779.92\n",
      "4768.84\n",
      "4756.65\n",
      "4743.15\n",
      "4728.41\n",
      "4712.53\n",
      "4696.44\n",
      "4680.56\n",
      "4664.89\n",
      "4649.31\n",
      "4633.29\n",
      "4617.87\n",
      "4602.29\n",
      "4587.03\n",
      "4571.66\n",
      "4556.19\n",
      "4540.29\n",
      "4523.93\n",
      "4507.16\n",
      "4490.05\n",
      "4472.5\n",
      "4454.51\n",
      "4435.9\n",
      "4416.83\n",
      "4397.45\n",
      "4378.0\n",
      "4358.24\n",
      "4338.31\n",
      "4317.97\n",
      "4297.07\n",
      "4275.6\n",
      "4254.13\n",
      "4232.27\n",
      "4210.03\n",
      "4187.26\n",
      "4163.94\n",
      "4140.06\n",
      "4115.59\n",
      "4090.52\n",
      "4064.83\n",
      "4039.17\n",
      "4013.79\n",
      "3987.92\n",
      "3961.58\n",
      "3934.75\n",
      "3907.44\n",
      "3879.65\n",
      "3851.35\n",
      "3822.55\n",
      "3793.22\n",
      "3764.68\n",
      "3739.47\n",
      "3713.86\n",
      "3687.38\n",
      "3660.11\n",
      "3632.16\n",
      "3603.6\n",
      "3574.52\n",
      "3545.2\n",
      "3515.93\n",
      "3486.39\n",
      "3456.63\n",
      "3426.88\n",
      "3399.33\n",
      "3372.01\n",
      "3343.31\n",
      "3313.51\n",
      "3284.21\n",
      "3256.32\n",
      "3228.59\n",
      "3200.98\n",
      "3173.49\n",
      "3146.1\n",
      "3118.5\n",
      "3090.42\n",
      "3061.78\n",
      "3032.58\n",
      "3004.31\n",
      "2975.8\n",
      "2947.27\n",
      "2918.44\n",
      "2889.34\n",
      "2860.37\n",
      "2831.49\n",
      "2807.14\n",
      "2781.94\n",
      "2756.14\n",
      "2729.49\n",
      "2703.45\n",
      "2677.14\n",
      "2651.01\n",
      "2625.36\n",
      "2599.07\n",
      "2574.03\n",
      "2549.04\n",
      "2523.95\n",
      "2498.74\n",
      "2473.36\n",
      "2449.33\n",
      "2424.63\n",
      "2400.15\n",
      "2375.84\n",
      "2351.25\n",
      "2325.61\n",
      "2300.03\n",
      "2275.85\n",
      "2252.33\n",
      "2228.04\n",
      "2202.68\n",
      "2176.98\n",
      "2152.21\n",
      "2127.28\n",
      "2102.14\n",
      "2076.25\n",
      "2049.98\n",
      "2023.26\n",
      "1996.15\n",
      "1968.65\n",
      "1941.68\n",
      "1914.32\n",
      "1887.43\n",
      "1861.42\n",
      "1834.09\n",
      "1806.34\n",
      "1777.55\n",
      "1747.51\n",
      "1716.59\n",
      "1684.69\n",
      "1651.84\n",
      "1618.52\n",
      "1583.8\n",
      "1549.08\n",
      "1516.09\n",
      "1483.26\n",
      "1452.58\n",
      "1420.86\n",
      "1389.27\n",
      "1357.55\n",
      "1327.09\n",
      "1297.43\n",
      "1266.62\n",
      "1235.26\n",
      "1205.56\n",
      "1175.35\n",
      "1143.82\n",
      "1114.53\n",
      "1085.19\n",
      "1055.34\n",
      "1027.83\n",
      "1001.57\n",
      "975.806\n",
      "948.943\n",
      "922.759\n",
      "897.351\n",
      "873.126\n",
      "849.786\n",
      "826.383\n",
      "802.702\n",
      "779.155\n",
      "756.25\n",
      "733.558\n",
      "711.057\n",
      "688.913\n",
      "667.13\n",
      "646.106\n",
      "625.945\n",
      "606.14\n",
      "586.982\n",
      "568.163\n",
      "549.593\n",
      "531.307\n",
      "513.343\n",
      "495.73\n",
      "478.472\n",
      "461.563\n",
      "444.986\n",
      "428.773\n",
      "412.944\n",
      "397.348\n",
      "382.025\n",
      "366.888\n",
      "351.892\n",
      "337.092\n",
      "323.002\n",
      "308.85\n",
      "294.653\n",
      "280.716\n",
      "267.936\n",
      "255.086\n",
      "242.734\n",
      "233.706\n",
      "224.458\n",
      "215.243\n",
      "206.156\n",
      "197.347\n",
      "188.93\n",
      "182.107\n",
      "175.66\n",
      "168.671\n",
      "161.148\n",
      "153.638\n",
      "147.644\n",
      "142.54\n",
      "137.885\n",
      "133.416\n",
      "129.017\n",
      "124.792\n",
      "120.648\n",
      "116.628\n",
      "112.978\n",
      "110.028\n",
      "107.309\n",
      "104.454\n",
      "101.545\n",
      "98.9665\n",
      "96.631\n",
      "94.4065\n",
      "92.25\n",
      "90.1323\n",
      "88.0436\n",
      "85.993\n",
      "83.9975\n",
      "82.0704\n",
      "80.241\n",
      "78.4247\n",
      "76.682\n",
      "75.0134\n",
      "73.3282\n",
      "71.6213\n",
      "69.9505\n",
      "68.3196\n",
      "66.7441\n",
      "65.2236\n",
      "63.7253\n",
      "62.2435\n",
      "60.7877\n",
      "59.3918\n",
      "58.0151\n",
      "56.6576\n",
      "55.3225\n",
      "54.0369\n",
      "52.7737\n",
      "51.554\n",
      "50.3526\n",
      "49.1784\n",
      "48.0383\n",
      "46.9187\n",
      "45.8199\n",
      "44.7515\n",
      "43.7018\n",
      "42.6865\n",
      "41.6942\n",
      "40.7181\n",
      "39.7819\n",
      "38.881\n",
      "38.0025\n",
      "37.134\n",
      "36.2919\n",
      "35.4694\n",
      "34.6648\n",
      "33.8734\n",
      "33.0996\n",
      "32.3455\n",
      "31.6133\n",
      "30.9025\n",
      "30.2283\n",
      "29.5334\n",
      "28.8891\n",
      "28.2521\n",
      "27.6154\n",
      "27.0332\n",
      "26.4212\n",
      "25.8376\n",
      "25.2863\n",
      "24.7314\n",
      "24.1967\n",
      "23.6824\n",
      "23.1806\n",
      "22.6887\n",
      "22.2077\n",
      "21.7376\n",
      "21.2789\n",
      "20.8318\n",
      "20.3982\n",
      "19.9886\n",
      "19.5725\n",
      "19.1683\n",
      "18.7847\n",
      "18.4089\n",
      "18.0417\n",
      "17.6801\n",
      "17.3329\n",
      "16.9929\n",
      "16.6621\n",
      "16.3453\n",
      "16.0314\n",
      "15.7221\n",
      "15.4409\n",
      "15.1507\n",
      "14.8592\n",
      "14.5897\n",
      "14.3252\n",
      "14.0652\n",
      "13.8126\n",
      "13.5663\n",
      "13.3284\n",
      "13.0946\n",
      "12.8741\n",
      "12.6455\n",
      "12.4325\n",
      "12.2236\n",
      "12.0138\n",
      "11.8068\n",
      "11.603\n",
      "11.4318\n",
      "11.2402\n",
      "11.0681\n",
      "10.9002\n",
      "10.741\n",
      "10.5779\n",
      "10.4168\n",
      "10.2637\n",
      "10.1144\n",
      "9.968\n",
      "9.82471\n",
      "9.6872\n",
      "9.56071\n",
      "9.4331\n",
      "9.30026\n",
      "9.16582\n",
      "9.05219\n",
      "8.92943\n",
      "8.81404\n",
      "8.70134\n",
      "8.59355\n",
      "8.48782\n",
      "8.38267\n",
      "8.28078\n",
      "8.18219\n",
      "8.08541\n",
      "7.99285\n",
      "7.90005\n",
      "7.80975\n",
      "7.72308\n",
      "7.63723\n",
      "7.55233\n",
      "7.47503\n",
      "7.38802\n",
      "7.31843\n",
      "7.24553\n",
      "7.15999\n",
      "7.06553\n",
      "6.97931\n",
      "6.92639\n",
      "6.83258\n",
      "6.75275\n",
      "6.68376\n",
      "6.6045\n",
      "6.52261\n",
      "6.43745\n",
      "6.35488\n",
      "6.2721\n",
      "6.19467\n",
      "6.11857\n",
      "6.04151\n",
      "5.96367\n",
      "5.88739\n",
      "5.81416\n",
      "5.742\n",
      "5.67093\n",
      "5.60384\n",
      "5.53867\n",
      "5.47413\n",
      "5.41213\n",
      "5.3526\n",
      "5.29136\n",
      "5.2308\n",
      "5.17319\n",
      "5.12108\n",
      "5.06792\n",
      "5.01192\n",
      "4.95555\n",
      "4.90691\n",
      "4.85791\n",
      "4.80871\n",
      "4.76093\n",
      "4.71558\n",
      "4.66922\n",
      "4.62364\n",
      "4.58163\n",
      "4.53782\n",
      "4.4932\n",
      "4.45151\n",
      "4.4109\n",
      "4.37101\n",
      "4.332\n",
      "4.29303\n",
      "4.25428\n",
      "4.21766\n",
      "4.18083\n",
      "4.14487\n",
      "4.10949\n",
      "4.07364\n",
      "4.04173\n",
      "4.00858\n",
      "3.97406\n",
      "3.94198\n",
      "3.90987\n",
      "3.87912\n",
      "3.84889\n",
      "3.81922\n",
      "3.78867\n",
      "3.75883\n",
      "3.73089\n",
      "3.7029\n",
      "3.67485\n",
      "3.64698\n",
      "3.62109\n",
      "3.59496\n",
      "3.56782\n",
      "3.54297\n",
      "3.51859\n",
      "3.49403\n",
      "3.47146\n",
      "3.44786\n",
      "3.4242\n",
      "3.39928\n",
      "3.37588\n",
      "3.35706\n",
      "3.33154\n",
      "3.3103\n",
      "3.28887\n",
      "3.26715\n",
      "3.24624\n",
      "3.22486\n",
      "3.20428\n",
      "3.18326\n",
      "3.16331\n",
      "3.14354\n",
      "3.12381\n",
      "3.10456\n",
      "3.08473\n",
      "3.0671\n",
      "3.05018\n",
      "3.02941\n",
      "3.01314\n",
      "2.99637\n",
      "2.97829\n",
      "2.96125\n",
      "2.94379\n",
      "2.92605\n",
      "2.91136\n",
      "2.89582\n",
      "2.8785\n",
      "2.86306\n",
      "2.84743\n",
      "2.83257\n",
      "2.81763\n",
      "2.8032\n",
      "2.78706\n",
      "2.7741\n",
      "2.76\n",
      "2.74495\n",
      "2.73227\n",
      "2.71886\n",
      "2.70454\n",
      "2.69011\n",
      "2.67777\n",
      "2.66568\n",
      "2.65295\n",
      "2.64008\n",
      "2.62703\n",
      "2.61358\n",
      "2.60173\n",
      "2.59096\n",
      "2.57892\n",
      "2.56579\n",
      "2.55367\n",
      "2.54367\n",
      "2.53197\n",
      "2.51968\n",
      "2.50956\n",
      "2.49873\n",
      "2.48734\n",
      "2.47662\n",
      "2.46533\n",
      "2.45409\n",
      "2.44454\n",
      "2.43434\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    X_batch = X_train.reshape(1, 23, 1)\n",
    "    y_batch = y_train.reshape(1, 23, 1)\n",
    "    sess.run(training_op, feed_dict = {X:X_batch, y:y_batch})\n",
    "    mse = loss.eval(feed_dict = {X:X_batch, y:y_batch})\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use output values (y_batch) as input to predict next 10 values in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(10):\n",
    "    X_new = y_batch\n",
    "    y_pred = sess.run(outputs, feed_dict={X:X_new})\n",
    "    pred_list.append(y_pred[:,22:,:])\n",
    "    y_batch = np.append(y_batch[:,1:,:],y_pred[:,22:,:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 205.42623901]]], dtype=float32),\n",
       " array([[[ 43.55230331]]], dtype=float32),\n",
       " array([[[ 44.43833542]]], dtype=float32),\n",
       " array([[[ 43.61295319]]], dtype=float32),\n",
       " array([[[ 44.867733]]], dtype=float32),\n",
       " array([[[ 44.47499847]]], dtype=float32),\n",
       " array([[[ 207.99891663]]], dtype=float32),\n",
       " array([[[ 44.42189407]]], dtype=float32),\n",
       " array([[[ 44.14424515]]], dtype=float32),\n",
       " array([[[ 43.9930687]]], dtype=float32)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### these are good predictions with spike every 6 months like in our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
